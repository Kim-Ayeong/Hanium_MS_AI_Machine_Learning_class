{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# 2019.11.17. 머신러닝 Regression with python3.6"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install --upgrade pandas==0.24.0",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already up-to-date: pandas==0.24.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (0.24.0)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pandas==0.24.0) (2.8.1)\nRequirement already satisfied, skipping upgrade: numpy>=1.12.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pandas==0.24.0) (1.16.2)\nRequirement already satisfied, skipping upgrade: pytz>=2011k in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pandas==0.24.0) (2019.3)\nRequirement already satisfied, skipping upgrade: six>=1.5 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas==0.24.0) (1.11.0)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 0. Package 가져오기"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\nprint(pd.__version__)\nprint(np.__version__)",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.23.4\n1.16.2\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1.  CSV 데이터 가져오기"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data = pd.read_csv('SR_Data.csv')\ndata.head(10)",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Age</th>\n      <th>Year</th>\n      <th>Salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>France</td>\n      <td>44.0</td>\n      <td>15.0</td>\n      <td>72000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Spain</td>\n      <td>27.0</td>\n      <td>3.0</td>\n      <td>48000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Germany</td>\n      <td>30.0</td>\n      <td>2.0</td>\n      <td>54000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Spain</td>\n      <td>38.0</td>\n      <td>NaN</td>\n      <td>61000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Germany</td>\n      <td>40.0</td>\n      <td>10.0</td>\n      <td>61000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>France</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>58000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Spain</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>52000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>France</td>\n      <td>48.0</td>\n      <td>NaN</td>\n      <td>79000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Germany</td>\n      <td>50.0</td>\n      <td>21.0</td>\n      <td>83000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>France</td>\n      <td>37.0</td>\n      <td>7.0</td>\n      <td>67000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   Country   Age  Year  Salary\n0   France  44.0  15.0   72000\n1    Spain  27.0   3.0   48000\n2  Germany  30.0   2.0   54000\n3    Spain  38.0   NaN   61000\n4  Germany  40.0  10.0   61000\n5   France  35.0   NaN   58000\n6    Spain   NaN   6.0   52000\n7   France  48.0   NaN   79000\n8  Germany  50.0  21.0   83000\n9   France  37.0   7.0   67000"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data.shape",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "(10, 4)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data.info()",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10 entries, 0 to 9\nData columns (total 4 columns):\nCountry    10 non-null object\nAge        9 non-null float64\nYear       7 non-null float64\nSalary     10 non-null int64\ndtypes: float64(2), int64(1), object(1)\nmemory usage: 400.0+ bytes\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data.isnull().sum()",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "Country    0\nAge        1\nYear       3\nSalary     0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2. feature/label 나누기"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# X = data[['Country', 'Age', 'Year']].to_numpy() 이런 방식으로는 사용하지 않음\n# y = data['Salary'].to_numpy()\n\n# X = data.iloc[:, :-1].to_numpy() # 2차원 이상 벡터는 대문자\n# y = data.iloc[:, -1].to_numpy() # 1차원 벡터는 소문자\n\nX = data.iloc[:, :-1].values\ny = data.iloc[:, -1].values\n\nprint(X)\nprint(y)",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[['France' 44.0 15.0]\n ['Spain' 27.0 3.0]\n ['Germany' 30.0 2.0]\n ['Spain' 38.0 nan]\n ['Germany' 40.0 10.0]\n ['France' 35.0 nan]\n ['Spain' nan 6.0]\n ['France' 48.0 nan]\n ['Germany' 50.0 21.0]\n ['France' 37.0 7.0]]\n[72000 48000 54000 61000 61000 58000 52000 79000 83000 67000]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3. Clean Missing Data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n\n# 각각 다른 컬럼을 채워주고 싶은 경우 fit, transform을 따로 시행\n# imputer.fit(X[:, 1:]) # nan값을 대체할 값 학습\n# X[:, 1:] = imputer.transform(X[:, 1:]) # 데이터에 nan값이 등장하면 위의 fit된 값으로 변경\n\n# 한번에 채워주고 싶은 경우\nX[:, 1:] = imputer.fit_transform(X[:, 1:]) \n\nprint(X)",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[['France' 44.0 15.0]\n ['Spain' 27.0 3.0]\n ['Germany' 30.0 2.0]\n ['Spain' 38.0 9.142857142857142]\n ['Germany' 40.0 10.0]\n ['France' 35.0 9.142857142857142]\n ['Spain' 38.77777777777778 6.0]\n ['France' 48.0 9.142857142857142]\n ['Germany' 50.0 21.0]\n ['France' 37.0 7.0]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(X[:, :2]) # 범위(, ) 포함 범위 주의! 앞은 포함 뒤는 포함 X",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[['France' 44.0]\n ['Spain' 27.0]\n ['Germany' 30.0]\n ['Spain' 38.0]\n ['Germany' 40.0]\n ['France' 35.0]\n ['Spain' 38.77777777777778]\n ['France' 48.0]\n ['Germany' 50.0]\n ['France' 37.0]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 도움말 보기\n?imputer",
      "execution_count": 40,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pd.DataFrame(X).isnull().sum()",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "0    0\n1    0\n2    0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## 4. Make Categorical"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 버전 에러를 없애고 싶을 때 아래 Label인코딩, onehot인코딩 대신 이것만 시행\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nct = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [0])], remainder='passthrough')\nXX = ct.fit_transform(X)\n\nprint(XX) ",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[1.0 0.0 0.0 44.0 15.0]\n [0.0 0.0 1.0 27.0 3.0]\n [0.0 1.0 0.0 30.0 2.0]\n [0.0 0.0 1.0 38.0 9.142857142857142]\n [0.0 1.0 0.0 40.0 10.0]\n [1.0 0.0 0.0 35.0 9.142857142857142]\n [0.0 0.0 1.0 38.77777777777778 6.0]\n [1.0 0.0 0.0 48.0 9.142857142857142]\n [0.0 1.0 0.0 50.0 21.0]\n [1.0 0.0 0.0 37.0 7.0]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 문자 변수를 숫자 변수로 변환\nfrom sklearn.preprocessing import LabelEncoder\n\nlabelEncoder = LabelEncoder()\nX[:, 0] = labelEncoder.fit_transform(X[:, 0])\n\nprint(X)",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[0 44.0 15.0]\n [2 27.0 3.0]\n [1 30.0 2.0]\n [2 38.0 9.142857142857142]\n [1 40.0 10.0]\n [0 35.0 9.142857142857142]\n [2 38.77777777777778 6.0]\n [0 48.0 9.142857142857142]\n [1 50.0 21.0]\n [0 37.0 7.0]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 범주 변수를 가변수화하기\nfrom sklearn.preprocessing import OneHotEncoder\n\nonehotEncoder = OneHotEncoder(categorical_features=[0])\nX = onehotEncoder.fit_transform(X).toarray()\n\nprint(X)",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[ 1.          0.          0.         44.         15.        ]\n [ 0.          0.          1.         27.          3.        ]\n [ 0.          1.          0.         30.          2.        ]\n [ 0.          0.          1.         38.          9.14285714]\n [ 0.          1.          0.         40.         10.        ]\n [ 1.          0.          0.         35.          9.14285714]\n [ 0.          0.          1.         38.77777778  6.        ]\n [ 1.          0.          0.         48.          9.14285714]\n [ 0.          1.          0.         50.         21.        ]\n [ 1.          0.          0.         37.          7.        ]]\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 5. Split Train/Test Set"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n\nprint(X_train)",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[ 1.          0.          0.         48.          9.14285714]\n [ 0.          1.          0.         30.          2.        ]\n [ 0.          0.          1.         27.          3.        ]\n [ 1.          0.          0.         37.          7.        ]\n [ 0.          0.          1.         38.          9.14285714]\n [ 1.          0.          0.         44.         15.        ]\n [ 0.          0.          1.         38.77777778  6.        ]\n [ 1.          0.          0.         35.          9.14285714]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6. Standardization"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\nX_train[:, 3:] = scaler.fit_transform(X_train[:, 3:])\nX_test[:, 3:] = scaler.fit_transform(X_test[:, 3:])\n\nprint(X_train)",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[1.         0.         0.         1.         0.54945055]\n [0.         1.         0.         0.14285714 0.        ]\n [0.         0.         1.         0.         0.07692308]\n [1.         0.         0.         0.47619048 0.38461538]\n [0.         0.         1.         0.52380952 0.54945055]\n [1.         0.         0.         0.80952381 1.        ]\n [0.         0.         1.         0.56084656 0.30769231]\n [1.         0.         0.         0.38095238 0.54945055]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 7. Train"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 1) Linear Regression"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LinearRegression\n\nregressor = LinearRegression()\nregressor.fit(X_train, y_train) # 학습",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "?LinearRegression # 속성의 default값 살펴보기",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Object `LinearRegression # 속성의 default값 살펴보기` not found.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 2) Decision Tree"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeRegressor\n\nregressor_tree = DecisionTreeRegressor()\nregressor_tree.fit(X_train, y_train)",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 52,
          "data": {
            "text/plain": "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n           max_leaf_nodes=None, min_impurity_decrease=0.0,\n           min_impurity_split=None, min_samples_leaf=1,\n           min_samples_split=2, min_weight_fraction_leaf=0.0,\n           presort=False, random_state=None, splitter='best')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 8. Predict(Scoring)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_pred = regressor.predict(X_test)\ny_pred_tree = regressor_tree.predict(X_test)\n\nprint(y_test)\nprint(y_pred)\nprint(y_pred_tree)",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[83000 61000]\n[72963.82803215 50662.6622963 ]\n[79000. 48000.]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## 9. Evaluate"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_absolute_error, mean_squared_error\n\nprint(\"MAE : \", mean_absolute_error(y_test, y_pred))\nprint(\"MAE_tree : \", mean_absolute_error(y_test, y_pred_tree))\n\nprint(\"MSE : \", mean_squared_error(y_test, y_pred))\nprint(\"MSE_tree : \", mean_squared_error(y_test, y_pred_tree))",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": "MAE :  10186.754835774522\nMAE_tree :  8500.0\nMSE :  103792649.28428817\nMSE_tree :  92500000.0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# 사이킷런의 모든 알고리즘 살펴보기\nfrom sklearn.utils.testing import all_estimators\nestimators = all_estimators()\n\nprint(estimators)",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[('ARDRegression', <class 'sklearn.linear_model.bayes.ARDRegression'>), ('AdaBoostClassifier', <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>), ('AdaBoostRegressor', <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>), ('AdditiveChi2Sampler', <class 'sklearn.kernel_approximation.AdditiveChi2Sampler'>), ('AffinityPropagation', <class 'sklearn.cluster.affinity_propagation_.AffinityPropagation'>), ('AgglomerativeClustering', <class 'sklearn.cluster.hierarchical.AgglomerativeClustering'>), ('BaggingClassifier', <class 'sklearn.ensemble.bagging.BaggingClassifier'>), ('BaggingRegressor', <class 'sklearn.ensemble.bagging.BaggingRegressor'>), ('BayesianGaussianMixture', <class 'sklearn.mixture.bayesian_mixture.BayesianGaussianMixture'>), ('BayesianRidge', <class 'sklearn.linear_model.bayes.BayesianRidge'>), ('BernoulliNB', <class 'sklearn.naive_bayes.BernoulliNB'>), ('BernoulliRBM', <class 'sklearn.neural_network.rbm.BernoulliRBM'>), ('Binarizer', <class 'sklearn.preprocessing.data.Binarizer'>), ('Birch', <class 'sklearn.cluster.birch.Birch'>), ('CCA', <class 'sklearn.cross_decomposition.cca_.CCA'>), ('CalibratedClassifierCV', <class 'sklearn.calibration.CalibratedClassifierCV'>), ('ComplementNB', <class 'sklearn.naive_bayes.ComplementNB'>), ('DBSCAN', <class 'sklearn.cluster.dbscan_.DBSCAN'>), ('DecisionTreeClassifier', <class 'sklearn.tree.tree.DecisionTreeClassifier'>), ('DecisionTreeRegressor', <class 'sklearn.tree.tree.DecisionTreeRegressor'>), ('DictionaryLearning', <class 'sklearn.decomposition.dict_learning.DictionaryLearning'>), ('ElasticNet', <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>), ('ElasticNetCV', <class 'sklearn.linear_model.coordinate_descent.ElasticNetCV'>), ('EllipticEnvelope', <class 'sklearn.covariance.elliptic_envelope.EllipticEnvelope'>), ('EmpiricalCovariance', <class 'sklearn.covariance.empirical_covariance_.EmpiricalCovariance'>), ('ExtraTreeClassifier', <class 'sklearn.tree.tree.ExtraTreeClassifier'>), ('ExtraTreeRegressor', <class 'sklearn.tree.tree.ExtraTreeRegressor'>), ('ExtraTreesClassifier', <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>), ('ExtraTreesRegressor', <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>), ('FactorAnalysis', <class 'sklearn.decomposition.factor_analysis.FactorAnalysis'>), ('FastICA', <class 'sklearn.decomposition.fastica_.FastICA'>), ('FeatureAgglomeration', <class 'sklearn.cluster.hierarchical.FeatureAgglomeration'>), ('FunctionTransformer', <class 'sklearn.preprocessing._function_transformer.FunctionTransformer'>), ('GaussianMixture', <class 'sklearn.mixture.gaussian_mixture.GaussianMixture'>), ('GaussianNB', <class 'sklearn.naive_bayes.GaussianNB'>), ('GaussianProcessClassifier', <class 'sklearn.gaussian_process.gpc.GaussianProcessClassifier'>), ('GaussianProcessRegressor', <class 'sklearn.gaussian_process.gpr.GaussianProcessRegressor'>), ('GaussianRandomProjection', <class 'sklearn.random_projection.GaussianRandomProjection'>), ('GenericUnivariateSelect', <class 'sklearn.feature_selection.univariate_selection.GenericUnivariateSelect'>), ('GradientBoostingClassifier', <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>), ('GradientBoostingRegressor', <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>), ('GraphLasso', <class 'sklearn.covariance.graph_lasso_.GraphLasso'>), ('GraphLassoCV', <class 'sklearn.covariance.graph_lasso_.GraphLassoCV'>), ('GraphicalLasso', <class 'sklearn.covariance.graph_lasso_.GraphicalLasso'>), ('GraphicalLassoCV', <class 'sklearn.covariance.graph_lasso_.GraphicalLassoCV'>), ('HuberRegressor', <class 'sklearn.linear_model.huber.HuberRegressor'>), ('Imputer', <class 'sklearn.preprocessing.imputation.Imputer'>), ('IncrementalPCA', <class 'sklearn.decomposition.incremental_pca.IncrementalPCA'>), ('IsolationForest', <class 'sklearn.ensemble.iforest.IsolationForest'>), ('Isomap', <class 'sklearn.manifold.isomap.Isomap'>), ('KBinsDiscretizer', <class 'sklearn.preprocessing._discretization.KBinsDiscretizer'>), ('KMeans', <class 'sklearn.cluster.k_means_.KMeans'>), ('KNeighborsClassifier', <class 'sklearn.neighbors.classification.KNeighborsClassifier'>), ('KNeighborsRegressor', <class 'sklearn.neighbors.regression.KNeighborsRegressor'>), ('KernelCenterer', <class 'sklearn.preprocessing.data.KernelCenterer'>), ('KernelDensity', <class 'sklearn.neighbors.kde.KernelDensity'>), ('KernelPCA', <class 'sklearn.decomposition.kernel_pca.KernelPCA'>), ('KernelRidge', <class 'sklearn.kernel_ridge.KernelRidge'>), ('LSHForest', <class 'sklearn.neighbors.approximate.LSHForest'>), ('LabelPropagation', <class 'sklearn.semi_supervised.label_propagation.LabelPropagation'>), ('LabelSpreading', <class 'sklearn.semi_supervised.label_propagation.LabelSpreading'>), ('Lars', <class 'sklearn.linear_model.least_angle.Lars'>), ('LarsCV', <class 'sklearn.linear_model.least_angle.LarsCV'>), ('Lasso', <class 'sklearn.linear_model.coordinate_descent.Lasso'>), ('LassoCV', <class 'sklearn.linear_model.coordinate_descent.LassoCV'>), ('LassoLars', <class 'sklearn.linear_model.least_angle.LassoLars'>), ('LassoLarsCV', <class 'sklearn.linear_model.least_angle.LassoLarsCV'>), ('LassoLarsIC', <class 'sklearn.linear_model.least_angle.LassoLarsIC'>), ('LatentDirichletAllocation', <class 'sklearn.decomposition.online_lda.LatentDirichletAllocation'>), ('LedoitWolf', <class 'sklearn.covariance.shrunk_covariance_.LedoitWolf'>), ('LinearDiscriminantAnalysis', <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>), ('LinearRegression', <class 'sklearn.linear_model.base.LinearRegression'>), ('LinearSVC', <class 'sklearn.svm.classes.LinearSVC'>), ('LinearSVR', <class 'sklearn.svm.classes.LinearSVR'>), ('LocalOutlierFactor', <class 'sklearn.neighbors.lof.LocalOutlierFactor'>), ('LocallyLinearEmbedding', <class 'sklearn.manifold.locally_linear.LocallyLinearEmbedding'>), ('LogisticRegression', <class 'sklearn.linear_model.logistic.LogisticRegression'>), ('LogisticRegressionCV', <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>), ('MDS', <class 'sklearn.manifold.mds.MDS'>), ('MLPClassifier', <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>), ('MLPRegressor', <class 'sklearn.neural_network.multilayer_perceptron.MLPRegressor'>), ('MaxAbsScaler', <class 'sklearn.preprocessing.data.MaxAbsScaler'>), ('MeanShift', <class 'sklearn.cluster.mean_shift_.MeanShift'>), ('MinCovDet', <class 'sklearn.covariance.robust_covariance.MinCovDet'>), ('MinMaxScaler', <class 'sklearn.preprocessing.data.MinMaxScaler'>), ('MiniBatchDictionaryLearning', <class 'sklearn.decomposition.dict_learning.MiniBatchDictionaryLearning'>), ('MiniBatchKMeans', <class 'sklearn.cluster.k_means_.MiniBatchKMeans'>), ('MiniBatchSparsePCA', <class 'sklearn.decomposition.sparse_pca.MiniBatchSparsePCA'>), ('MissingIndicator', <class 'sklearn.impute.MissingIndicator'>), ('MultiTaskElasticNet', <class 'sklearn.linear_model.coordinate_descent.MultiTaskElasticNet'>), ('MultiTaskElasticNetCV', <class 'sklearn.linear_model.coordinate_descent.MultiTaskElasticNetCV'>), ('MultiTaskLasso', <class 'sklearn.linear_model.coordinate_descent.MultiTaskLasso'>), ('MultiTaskLassoCV', <class 'sklearn.linear_model.coordinate_descent.MultiTaskLassoCV'>), ('MultinomialNB', <class 'sklearn.naive_bayes.MultinomialNB'>), ('NMF', <class 'sklearn.decomposition.nmf.NMF'>), ('NearestCentroid', <class 'sklearn.neighbors.nearest_centroid.NearestCentroid'>), ('NearestNeighbors', <class 'sklearn.neighbors.unsupervised.NearestNeighbors'>), ('Normalizer', <class 'sklearn.preprocessing.data.Normalizer'>), ('NuSVC', <class 'sklearn.svm.classes.NuSVC'>), ('NuSVR', <class 'sklearn.svm.classes.NuSVR'>), ('Nystroem', <class 'sklearn.kernel_approximation.Nystroem'>), ('OAS', <class 'sklearn.covariance.shrunk_covariance_.OAS'>), ('OneClassSVM', <class 'sklearn.svm.classes.OneClassSVM'>), ('OrthogonalMatchingPursuit', <class 'sklearn.linear_model.omp.OrthogonalMatchingPursuit'>), ('OrthogonalMatchingPursuitCV', <class 'sklearn.linear_model.omp.OrthogonalMatchingPursuitCV'>), ('PCA', <class 'sklearn.decomposition.pca.PCA'>), ('PLSCanonical', <class 'sklearn.cross_decomposition.pls_.PLSCanonical'>), ('PLSRegression', <class 'sklearn.cross_decomposition.pls_.PLSRegression'>), ('PLSSVD', <class 'sklearn.cross_decomposition.pls_.PLSSVD'>), ('PassiveAggressiveClassifier', <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'>), ('PassiveAggressiveRegressor', <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveRegressor'>), ('Perceptron', <class 'sklearn.linear_model.perceptron.Perceptron'>), ('PowerTransformer', <class 'sklearn.preprocessing.data.PowerTransformer'>), ('QuadraticDiscriminantAnalysis', <class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'>), ('QuantileTransformer', <class 'sklearn.preprocessing.data.QuantileTransformer'>), ('RANSACRegressor', <class 'sklearn.linear_model.ransac.RANSACRegressor'>), ('RBFSampler', <class 'sklearn.kernel_approximation.RBFSampler'>), ('RadiusNeighborsClassifier', <class 'sklearn.neighbors.classification.RadiusNeighborsClassifier'>), ('RadiusNeighborsRegressor', <class 'sklearn.neighbors.regression.RadiusNeighborsRegressor'>), ('RandomForestClassifier', <class 'sklearn.ensemble.forest.RandomForestClassifier'>), ('RandomForestRegressor', <class 'sklearn.ensemble.forest.RandomForestRegressor'>), ('RandomizedLasso', <class 'sklearn.linear_model.randomized_l1.RandomizedLasso'>), ('RandomizedLogisticRegression', <class 'sklearn.linear_model.randomized_l1.RandomizedLogisticRegression'>), ('Ridge', <class 'sklearn.linear_model.ridge.Ridge'>), ('RidgeCV', <class 'sklearn.linear_model.ridge.RidgeCV'>), ('RidgeClassifier', <class 'sklearn.linear_model.ridge.RidgeClassifier'>), ('RidgeClassifierCV', <class 'sklearn.linear_model.ridge.RidgeClassifierCV'>), ('RobustScaler', <class 'sklearn.preprocessing.data.RobustScaler'>), ('SGDClassifier', <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>), ('SGDRegressor', <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'>), ('SVC', <class 'sklearn.svm.classes.SVC'>), ('SVR', <class 'sklearn.svm.classes.SVR'>), ('SelectFdr', <class 'sklearn.feature_selection.univariate_selection.SelectFdr'>), ('SelectFpr', <class 'sklearn.feature_selection.univariate_selection.SelectFpr'>), ('SelectFwe', <class 'sklearn.feature_selection.univariate_selection.SelectFwe'>), ('SelectKBest', <class 'sklearn.feature_selection.univariate_selection.SelectKBest'>), ('SelectPercentile', <class 'sklearn.feature_selection.univariate_selection.SelectPercentile'>), ('ShrunkCovariance', <class 'sklearn.covariance.shrunk_covariance_.ShrunkCovariance'>), ('SimpleImputer', <class 'sklearn.impute.SimpleImputer'>), ('SkewedChi2Sampler', <class 'sklearn.kernel_approximation.SkewedChi2Sampler'>), ('SparsePCA', <class 'sklearn.decomposition.sparse_pca.SparsePCA'>), ('SparseRandomProjection', <class 'sklearn.random_projection.SparseRandomProjection'>), ('SpectralBiclustering', <class 'sklearn.cluster.bicluster.SpectralBiclustering'>), ('SpectralClustering', <class 'sklearn.cluster.spectral.SpectralClustering'>), ('SpectralCoclustering', <class 'sklearn.cluster.bicluster.SpectralCoclustering'>), ('SpectralEmbedding', <class 'sklearn.manifold.spectral_embedding_.SpectralEmbedding'>), ('StandardScaler', <class 'sklearn.preprocessing.data.StandardScaler'>), ('TSNE', <class 'sklearn.manifold.t_sne.TSNE'>), ('TheilSenRegressor', <class 'sklearn.linear_model.theil_sen.TheilSenRegressor'>), ('TransformedTargetRegressor', <class 'sklearn.compose._target.TransformedTargetRegressor'>), ('VarianceThreshold', <class 'sklearn.feature_selection.variance_threshold.VarianceThreshold'>), ('_BaseEncoder', <class 'sklearn.preprocessing._encoders._BaseEncoder'>), ('_BaseRidgeCV', <class 'sklearn.linear_model.ridge._BaseRidgeCV'>), ('_BinaryGaussianProcessClassifierLaplace', <class 'sklearn.gaussian_process.gpc._BinaryGaussianProcessClassifierLaplace'>), ('_ConstantPredictor', <class 'sklearn.multiclass._ConstantPredictor'>), ('_RidgeGCV', <class 'sklearn.linear_model.ridge._RidgeGCV'>)]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(estimators.count)",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<built-in method count of list object at 0x7ff16413bcc8>\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}